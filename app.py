import os
import numpy as np
import cv2
import tempfile
import requests
import h5py
import streamlit as st
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import Dense

# ğŸ”¹ Hugging Face æ¨¡å‹ä¸‹è¼‰ç¶²å€
MODEL_URL = "https://huggingface.co/wuwuwu123123/deepfake/resolve/main/deepfake_cnn_model.h5"

@st.cache_resource
def download_model():
    model_path = os.path.join(tempfile.gettempdir(), "deepfake_cnn_model.h5")

    if not os.path.exists(model_path):
        response = requests.get(MODEL_URL)
        if response.status_code == 200:
            with open(model_path, "wb") as f:
                f.write(response.content)
        else:
            st.error("âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼Œè«‹ç¢ºèª Hugging Face æ¨¡å‹ç¶²å€æ˜¯å¦æ­£ç¢ºã€‚")
            raise Exception("æ¨¡å‹ä¸‹è¼‰å¤±æ•—ã€‚")

    try:
        with h5py.File(model_path, 'r') as f:
            pass
    except OSError as e:
        st.error("âŒ æ¨¡å‹æª”æ¡ˆç„¡æ³•è®€å–ï¼Œå¯èƒ½æ˜¯æå£æˆ–æ ¼å¼éŒ¯èª¤ã€‚")
        raise

    return load_model(model_path)

# ğŸ”¹ è¼‰å…¥æ¨¡å‹
try:
    custom_model = download_model()
except Exception as e:
    st.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    st.stop()

# ğŸ”¹ ResNet50 æ¨¡å‹å»ºç«‹
resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))
resnet_classifier = Sequential([
    resnet_model,
    Dense(1, activation='sigmoid')
])
resnet_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ğŸ”¹ é è™•ç†å‡½æ•¸ for both models
def preprocess_for_models(img):
    img_resized = cv2.resize(img, (256, 256))  # é‡æ–°èª¿æ•´å¤§å°ç‚º 256x256

    # For ResNet50
    resnet_input = preprocess_input(np.expand_dims(img_resized, axis=0))

    # For Custom CNN (CLAHE gray enhancement)
    gray = cv2.cvtColor(img_resized, cv2.COLOR_BGR2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    clahe_rgb = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)
    custom_input = np.expand_dims(clahe_rgb / 255.0, axis=0)

    return resnet_input, custom_input, img_resized

# ğŸ”¹ åµæ¸¬å½±ç‰‡ä¸¦ç”Ÿæˆæ–°å½±ç‰‡
def process_video_and_generate_result(video_file):
    # å°‡ä¸Šå‚³çš„å½±ç‰‡ä¿å­˜ç‚ºè‡¨æ™‚æ–‡ä»¶
    temp_video_path = os.path.join(tempfile.gettempdir(), "temp_video.mp4")
    with open(temp_video_path, "wb") as f:
        f.write(video_file.read())

    # ä½¿ç”¨ OpenCV ä¾†è®€å–å½±ç‰‡
    cap = cv2.VideoCapture(temp_video_path)

    # å–å¾—å½±ç‰‡çš„å¹€ç‡èˆ‡å¤§å°
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    # è¨­å®šè¼¸å‡ºçš„å½±ç‰‡è·¯å¾‘
    output_video_path = os.path.join(tempfile.gettempdir(), "processed_video.mp4")
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # è¨­å®šå½±ç‰‡ç·¨ç¢¼
    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))

    frame_count = 0
    processed_frame_count = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break  # å½±ç‰‡è®€å–çµæŸ

        # æ¯ 5 å¹€è™•ç†ä¸€æ¬¡
        if frame_count % 5 == 0:
            try:
                # é€²è¡Œåœ–ç‰‡é è™•ç†
                resnet_input, custom_input, display_img = preprocess_for_models(frame)

                # é æ¸¬
                resnet_pred = resnet_classifier.predict(resnet_input)[0][0]
                custom_pred = custom_model.predict(custom_input)[0][0]

                # åˆä½µçµæœ
                combined_pred = (resnet_pred + custom_pred) / 2  # é€™è£¡ç°¡å–®å–å¹³å‡
                label = "Deepfake" if combined_pred > 0.5 else "Real"
                confidence = combined_pred if combined_pred > 0.5 else 1 - combined_pred

                # åœ¨å½±åƒä¸Šç¹ªè£½æ¨™ç±¤èˆ‡ä¿¡å¿ƒåˆ†æ•¸
                cv2.putText(frame, f"{label} ({confidence:.2%})", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)

                # å¯«å…¥æ¯ä¸€å¹€
                out.write(frame)
                processed_frame_count += 1
            except Exception as e:
                st.error(f"âŒ è™•ç†å½±åƒå¹€æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                st.write(f"éŒ¯èª¤è©³æƒ…: {str(e)}")
                break
        frame_count += 1

    cap.release()
    out.release()

    return output_video_path

# ğŸ”¹ Streamlit App
st.title("ğŸ•µï¸ Deepfake åµæ¸¬ App")

uploaded_file = st.file_uploader("ğŸ“¤ ä¸Šå‚³ä¸€å¼µåœ–ç‰‡æˆ–å½±ç‰‡", type=["jpg", "jpeg", "png", "mp4", "mov"])
if uploaded_file is not None:
    try:
        if uploaded_file.type in ["image/jpeg", "image/png", "image/jpg"]:
            # é€²è¡Œåœ–ç‰‡é è™•ç†ä¸¦é¡¯ç¤ºçµæœ
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            st.image(file_bytes, caption="ä½ ä¸Šå‚³çš„åœ–ç‰‡", use_container_width=True)

            # é€²è¡Œé è™•ç†ä¸¦ç²å¾—æ¨¡å‹è¼¸å…¥
            resnet_input, custom_input, display_img = preprocess_for_models(file_bytes)

            # é æ¸¬
            resnet_pred = resnet_classifier.predict(resnet_input)[0][0]
            custom_pred = custom_model.predict(custom_input)[0][0]

            # åˆä½µçµæœ
            combined_pred = (resnet_pred + custom_pred) / 2  # é€™è£¡ç°¡å–®å–å¹³å‡
            label = "Deepfake" if combined_pred > 0.5 else "Real"
            confidence = combined_pred if combined_pred > 0.5 else 1 - combined_pred

            # é¡¯ç¤ºçµæœ
            st.markdown(f"### ğŸ§‘â€âš–ï¸ æœ€çµ‚é æ¸¬çµæœ: **{label}** ({confidence:.2%})")

        elif uploaded_file.type in ["video/mp4", "video/quicktime"]:
            # è™•ç†å½±ç‰‡ä¸¦ç”Ÿæˆçµæœ
            st.markdown("### ğŸ“½ï¸ æ­£åœ¨è™•ç†å½±ç‰‡...")
            processed_video_path = process_video_and_generate_result(uploaded_file)

            # é¡¯ç¤ºè™•ç†å¾Œçš„å½±ç‰‡
            st.video(processed_video_path)

    except Exception as e:
        st.error(f"âŒ ç™¼ç”ŸéŒ¯èª¤: {e}")
        st.write(f"éŒ¯èª¤è©³æƒ…: {str(e)}")
