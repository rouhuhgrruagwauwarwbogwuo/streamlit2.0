import os
import tempfile
import cv2
import numpy as np
import streamlit as st
from tensorflow.keras.models import load_model, Sequential
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import Dense

# ğŸ”¹ æ¨¡å‹ä¸‹è¼‰ (å‡è¨­å·²ç¶“ä¸‹è¼‰)
MODEL_URL = "https://huggingface.co/wuwuwu123123/deepfake/resolve/main/deepfake_cnn_model.h5"

@st.cache_resource
def download_model():
    model_path = os.path.join(tempfile.gettempdir(), "deepfake_cnn_model.h5")

    if not os.path.exists(model_path):
        response = requests.get(MODEL_URL)
        if response.status_code == 200:
            with open(model_path, "wb") as f:
                f.write(response.content)
        else:
            st.error("âŒ æ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼Œè«‹ç¢ºèª Hugging Face æ¨¡å‹ç¶²å€æ˜¯å¦æ­£ç¢ºã€‚")
            raise Exception("æ¨¡å‹ä¸‹è¼‰å¤±æ•—ã€‚")

    return load_model(model_path)

# ğŸ”¹ è¼‰å…¥è‡ªè¨‚æ¨¡å‹
custom_model = download_model()

# ğŸ”¹ ResNet50 æ¨¡å‹å»ºç«‹
resnet_model = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(256, 256, 3))
resnet_classifier = Sequential([
    resnet_model,
    Dense(1, activation='sigmoid')
])
resnet_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ğŸ”¹ é è™•ç†å‡½æ•¸
def preprocess_for_models(img):
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_resized = cv2.resize(img_rgb, (256, 256))

    # For ResNet50
    resnet_input = preprocess_input(np.expand_dims(img_resized, axis=0))

    # For Custom CNN (CLAHE gray enhancement)
    gray = cv2.cvtColor(img_resized, cv2.COLOR_RGB2GRAY)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(gray)
    clahe_rgb = cv2.cvtColor(enhanced, cv2.COLOR_GRAY2RGB)
    custom_input = np.expand_dims(clahe_rgb / 255.0, axis=0)

    return resnet_input, custom_input, img_rgb

# ğŸ”¹ è™•ç†å½±ç‰‡ä¸¦ç”Ÿæˆçµæœ
def process_video_and_generate_result(uploaded_file):
    video_bytes = uploaded_file.read()
    video_path = os.path.join(tempfile.gettempdir(), "uploaded_video.mp4")

    # å„²å­˜å½±ç‰‡è‡³è‡¨æ™‚æª”æ¡ˆ
    with open(video_path, "wb") as f:
        f.write(video_bytes)

    # æ‰“é–‹å½±ç‰‡é€²è¡Œè™•ç†
    cap = cv2.VideoCapture(video_path)
    
    # æª¢æŸ¥å½±ç‰‡æ˜¯å¦èƒ½å¤ æ‰“é–‹
    if not cap.isOpened():
        st.error("âŒ ç„¡æ³•æ‰“é–‹å½±ç‰‡æª”æ¡ˆï¼")
        return None

    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # è¨­å®šå½±ç‰‡ç·¨ç¢¼
    output_path = os.path.join(tempfile.gettempdir(), "processed_video.mp4")
    
    # è¨­å®šå½±ç‰‡è¼¸å‡ºæ ¼å¼
    out = cv2.VideoWriter(output_path, fourcc, 20.0, (frame_width, frame_height))  # 20.0 æ˜¯ FPS

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.warning("âŒ è®€å–å½±ç‰‡å¹€æ™‚å‡ºç¾éŒ¯èª¤æˆ–å½±ç‰‡å·²çµæŸã€‚")
            break
        
        # é è™•ç†æ¯ä¸€å¹€åœ–åƒ
        resnet_input, custom_input, display_img = preprocess_for_models(frame)
        
        # é æ¸¬
        resnet_pred = resnet_classifier.predict(resnet_input)[0][0]
        custom_pred = custom_model.predict(custom_input)[0][0]

        # åˆä½µçµæœ
        resnet_label = "Deepfake" if resnet_pred > 0.5 else "Real"
        custom_label = "Deepfake" if custom_pred > 0.5 else "Real"
        resnet_confidence = resnet_pred if resnet_pred > 0.5 else 1 - resnet_pred
        custom_confidence = custom_pred if custom_pred > 0.5 else 1 - custom_pred

        # æ¨™è¨»é¡¯ç¤º
        color_resnet = (0, 0, 255) if resnet_pred > 0.5 else (0, 255, 0)
        color_custom = (0, 0, 255) if custom_pred > 0.5 else (0, 255, 0)
        
        # åœ¨æ¯ä¸€å¹€ä¸ŠåŠ ä¸Šé æ¸¬çµæœæ–‡å­—
        cv2.putText(frame, f"ResNet: {resnet_label} ({resnet_confidence:.2%})", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color_resnet, 2)
        cv2.putText(frame, f"CNN: {custom_label} ({custom_confidence:.2%})", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, color_custom, 2)

        # å¯«å…¥æ¯ä¸€å¹€
        out.write(frame)

    # é‡‹æ”¾è³‡æº
    cap.release()
    out.release()

    return output_path

# ğŸ”¹ Streamlit App é¡¯ç¤º
st.title("ğŸ•µï¸ Deepfake åµæ¸¬ App")

uploaded_video = st.file_uploader("ğŸ“¤ ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov", "avi"])
if uploaded_video is not None:
    output_video_path = process_video_and_generate_result(uploaded_video)
    
    if output_video_path:
        # é¡¯ç¤ºè™•ç†å¾Œçš„å½±ç‰‡
        st.video(output_video_path)
