import numpy as np
import streamlit as st
import cv2
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from PIL import Image
from mtcnn import MTCNN
import tempfile
import os
import requests

# ğŸ”¹ é é¢è¨­å®šéœ€æ”¾æœ€ä¸Šé¢
st.set_page_config(page_title="Deepfake åµæ¸¬å™¨", layout="wide")
st.title("ğŸ§  Deepfake åœ–ç‰‡èˆ‡å½±ç‰‡åµæ¸¬å™¨")

# ğŸ”¹ ä¸‹è¼‰è‡ªè¨‚ CNN æ¨¡å‹
def download_model():
    model_url = "https://huggingface.co/wuwuwu123123/deepfakemodel2/resolve/main/deepfake_cnn_model.h5"
    model_filename = "deepfake_cnn_model.h5"
    if not os.path.exists(model_filename):
        response = requests.get(model_url)
        if response.status_code == 200:
            with open(model_filename, "wb") as f:
                f.write(response.content)
            print("æ¨¡å‹å·²ä¸‹è¼‰")
        else:
            print(f"æ¨¡å‹ä¸‹è¼‰å¤±æ•—ï¼š{response.status_code}")
            return None
    return model_filename

# ğŸ”¹ è¼‰å…¥ ResNet50 æ¨¡å‹
resnet_base = ResNet50(weights='imagenet', include_top=False, pooling='avg', input_shape=(224, 224, 3))
resnet_classifier = Sequential([
    resnet_base,
    Dense(1, activation='sigmoid')
])
resnet_classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ğŸ”¹ è¼‰å…¥è‡ªè¨‚ CNN æ¨¡å‹
model_path = download_model()
custom_model = load_model(model_path) if model_path else None

# ğŸ”¹ åˆå§‹åŒ–äººè‡‰åµæ¸¬å™¨
detector = MTCNN()

# ğŸ”¹ æ“·å–è‡‰éƒ¨å€åŸŸ
def extract_face(pil_img):
    img_array = np.array(pil_img)
    results = detector.detect_faces(img_array)
    if results:
        x, y, w, h = results[0]['box']
        face = img_array[y:y+h, x:x+w]
        face_pil = Image.fromarray(face).resize((224, 224))
        return face_pil
    return None

# ğŸ”¹ ä¸­å¿ƒè£åˆ‡
def center_crop(img, target_size=(224, 224)):
    width, height = img.size
    new_w, new_h = target_size
    left = (width - new_w) // 2
    top = (height - new_h) // 2
    return img.crop((left, top, left + new_w, top + new_h))

# ğŸ”¹ é è™•ç†åœ–ç‰‡
def preprocess_for_both_models(img):
    img = img.resize((256, 256), Image.Resampling.LANCZOS)
    img = center_crop(img, (224, 224))
    img_array = np.array(img)

    # åŠ ä¸Š Gaussian Blurï¼ˆé›–ç„¶è®“åœ–ç‰‡è®Šè—ï¼Œä½†åµæ¸¬æ›´æº–ï¼‰
    img_array = cv2.GaussianBlur(img_array, (3, 3), 0)

    resnet_input = preprocess_input(np.expand_dims(img_array, axis=0))
    custom_input = np.expand_dims(img_array / 255.0, axis=0)

    return resnet_input, custom_input

# ğŸ”¹ é æ¸¬
def predict_with_both_models(img):
    resnet_input, custom_input = preprocess_for_both_models(img)
    resnet_pred = resnet_classifier.predict(resnet_input)[0][0]
    resnet_label = "Deepfake" if resnet_pred > 0.5 else "Real"
    custom_pred = custom_model.predict(custom_input)[0][0] if custom_model else 0
    custom_label = "Deepfake" if custom_pred > 0.5 else "Real"
    return resnet_label, resnet_pred, custom_label, custom_pred

# ğŸ”¹ é¡¯ç¤ºé æ¸¬
def show_prediction(img):
    resnet_label, resnet_conf, custom_label, custom_conf = predict_with_both_models(img)
    st.subheader(f"ResNet50ï¼š{resnet_label}ï¼ˆ{resnet_conf:.2%}ï¼‰")
    st.subheader(f"Custom CNNï¼š{custom_label}ï¼ˆ{custom_conf:.2%}ï¼‰")

# ğŸ”¹ ä»‹é¢å€å¡Š
tab1, tab2 = st.tabs(["ğŸ–¼ï¸ åœ–ç‰‡åµæ¸¬", "ğŸ¥ å½±ç‰‡åµæ¸¬"])

# ---------- åœ–ç‰‡ ----------
with tab1:
    st.header("åœ–ç‰‡åµæ¸¬")
    uploaded_image = st.file_uploader("ä¸Šå‚³åœ–ç‰‡", type=["jpg", "jpeg", "png"])
    if uploaded_image:
        pil_img = Image.open(uploaded_image).convert("RGB")
        st.image(pil_img, caption="åŸå§‹åœ–ç‰‡", use_container_width=True)

        face_img = extract_face(pil_img)
        if face_img:
            st.image(face_img, caption="åµæ¸¬åˆ°çš„äººè‡‰", width=300)
            show_prediction(face_img)
        else:
            st.info("æœªåµæ¸¬åˆ°äººè‡‰ï¼Œä½¿ç”¨æ•´å¼µåœ–ç‰‡é æ¸¬")
            show_prediction(pil_img)

# ---------- å½±ç‰‡ ----------
with tab2:
    st.header("å½±ç‰‡åµæ¸¬ï¼ˆæ¯ 10 å¹€å– 1 å¼µï¼‰")
    uploaded_video = st.file_uploader("ä¸Šå‚³å½±ç‰‡", type=["mp4", "mov", "avi"])
    if uploaded_video:
        st.video(uploaded_video)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
            tmp.write(uploaded_video.read())
            video_path = tmp.name

        st.info("å½±ç‰‡è™•ç†ä¸­ï¼Œåƒ…é¡¯ç¤ºç¬¬ä¸€å€‹æˆåŠŸåˆ†æçš„å¹€")
        cap = cv2.VideoCapture(video_path)
        frame_idx = 0
        found = False

        while cap.isOpened() and not found:
            ret, frame = cap.read()
            if not ret:
                break
            if frame_idx % 10 == 0:
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_pil = Image.fromarray(frame_rgb)
                face_img = extract_face(frame_pil)
                if face_img:
                    st.image(face_img, caption=f"ç¬¬ {frame_idx} å¹€åµæ¸¬åˆ°äººè‡‰", width=300)
                    show_prediction(face_img)
                    found = True
            frame_idx += 1
        cap.release()

        if not found:
            st.warning("å½±ç‰‡ä¸­æœªåµæ¸¬åˆ°å¯ç”¨äººè‡‰")
